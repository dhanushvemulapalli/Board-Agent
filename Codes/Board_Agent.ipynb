{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "z4m7ZQJzlIo1",
        "outputId": "c8909351-38e6-4804-b409-751c70d8b66a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.6-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.12/dist-packages (0.4.16)\n",
            "Collecting langsmith\n",
            "  Downloading langsmith-0.4.21-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.10-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.74)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.4-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith) (3.11.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langsmith) (25.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.24.0)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting langchain-core>=0.1 (from langgraph)\n",
            "  Downloading langchain_core-0.3.75-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith) (2.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Downloading langgraph-0.6.6-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.4.21-py3-none-any.whl (378 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.5/378.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.1.10-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.75-py3-none-any.whl (443 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.4-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, ormsgpack, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, google-ai-generativelanguage, langgraph-prebuilt, langchain-google-genai, langgraph\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.4.16\n",
            "    Uninstalling langsmith-0.4.16:\n",
            "      Successfully uninstalled langsmith-0.4.16\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.74\n",
            "    Uninstalling langchain-core-0.3.74:\n",
            "      Successfully uninstalled langchain-core-0.3.74\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain-core-0.3.75 langchain-google-genai-2.1.10 langgraph-0.6.6 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.4 langsmith-0.4.21 ormsgpack-1.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "f88a5d0f65574b82b4a3338261cb2eea"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -U langgraph langsmith langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1KqdvNxKk66o"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from typing import TypedDict, List\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5XyAk90lHXz",
        "outputId": "af63599a-5a64-441b-c896-f5fac8ee2d25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google AI API key: ··········\n"
          ]
        }
      ],
      "source": [
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XyXE2QqP87xZ"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-2.0-flash-thinking-exp-01-21\",\n",
        "        temperature=0.2\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7YLl5WbJlk0w"
      },
      "outputs": [],
      "source": [
        "from langgraph.channels import LastValue\n",
        "from typing import TypedDict\n",
        "\n",
        "# ✅ Correct usage\n",
        "class ReviewState(TypedDict):\n",
        "    proposal: LastValue[str]   # proposal is \"last value\" channel of type str\n",
        "    legal_feedback: str\n",
        "    ethics_feedback: str\n",
        "    technical_feedback: str\n",
        "    financial_feedback: str\n",
        "    policy_feedback: str\n",
        "    final_verdict: str\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ctTV802tkntX"
      },
      "outputs": [],
      "source": [
        "# Define agents with concise, structured prompts\n",
        "def legal_advisor(state: ReviewState) -> ReviewState:\n",
        "    print(\"Inside legal_advisor \")\n",
        "    msg = f\"\"\"\n",
        "You are a Legal Advisor.\n",
        "Proposal: {state['proposal']}\n",
        "Task: Identify legal risks under Indian Penal Code (IPC) and suggest modifications if needed.\n",
        "Respond clearly with:\n",
        "- Issues\n",
        "- Suggested Fixes\n",
        "- Verdict (Legal/Not Legal)\n",
        "\"\"\"\n",
        "    response = llm.invoke(msg).content\n",
        "    state[\"legal_feedback\"] = response\n",
        "    return state\n",
        "\n",
        "\n",
        "def ethics_expert(state: ReviewState) -> ReviewState:\n",
        "    print(\"Inside ethics_expert \")\n",
        "\n",
        "    msg = f\"\"\"\n",
        "You are an Ethics Expert.\n",
        "Proposal: {state['proposal']}\n",
        "Task: Highlight ethical concerns and fairness issues.\n",
        "Respond with:\n",
        "- Key Ethical Risks\n",
        "- Mitigation Suggestions\n",
        "- Verdict (Ethical/Not Ethical)\n",
        "\"\"\"\n",
        "    response = llm.invoke(msg).content\n",
        "    state[\"ethics_feedback\"] = response\n",
        "    return state\n",
        "\n",
        "\n",
        "def financial_analyst(state: ReviewState) -> ReviewState:\n",
        "    print(\"Inside financial_analyst \")\n",
        "\n",
        "    msg = f\"\"\"\n",
        "You are a Financial Analyst.\n",
        "Proposal: {state['proposal']}\n",
        "Task: Assess costs, ROI, and sustainability.\n",
        "Respond with:\n",
        "- Estimated Costs\n",
        "- ROI & Risks\n",
        "- Verdict (Financially Viable/Not Viable)\n",
        "\"\"\"\n",
        "    response = llm.invoke(msg).content\n",
        "    state[\"financial_feedback\"] = response\n",
        "    return state\n",
        "\n",
        "\n",
        "def technical_analyst(state: ReviewState) -> ReviewState:\n",
        "    print(\"Inside technical_analyst \")\n",
        "\n",
        "    msg = f\"\"\"\n",
        "You are a Technical Analyst.\n",
        "Proposal: {state['proposal']}\n",
        "Task: Evaluate feasibility, technical risks, and limitations.\n",
        "Respond with:\n",
        "- Feasibility Issues\n",
        "- Known Limitations\n",
        "- Verdict (Feasible/Not Feasible)\n",
        "\"\"\"\n",
        "    response = llm.invoke(msg).content\n",
        "    state[\"technical_feedback\"] = response\n",
        "    return state\n",
        "\n",
        "\n",
        "def final_verdict(state: ReviewState) -> ReviewState:\n",
        "    print(\"Inside final_verdict \")\n",
        "\n",
        "    summary_prompt = f\"\"\"\n",
        "Board Review Summary:\n",
        "\n",
        "Legal: {state['legal_feedback']}\n",
        "Ethics: {state['ethics_feedback']}\n",
        "Financial: {state['financial_feedback']}\n",
        "Technical: {state['technical_feedback']}\n",
        "\n",
        "Task: Provide a final verdict.\n",
        "Answer with:\n",
        "- Overall Risk Level (Low/Medium/High)\n",
        "- Deployment Recommendation (Yes/No)\n",
        "- Short Rationale\n",
        "\"\"\"\n",
        "    response = llm.invoke(summary_prompt).content\n",
        "    state[\"final_verdict\"] = response\n",
        "    return state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qLtQWH60loQg"
      },
      "outputs": [],
      "source": [
        "# Build LangGraph\n",
        "builder = StateGraph(ReviewState)\n",
        "\n",
        "builder.add_node(\"legal_advisor\", legal_advisor)\n",
        "builder.add_node(\"ethics_expert\", ethics_expert)\n",
        "builder.add_node(\"financial_analyst\", financial_analyst)\n",
        "builder.add_node(\"technical_analyst\", technical_analyst)\n",
        "builder.add_node(\"final_verdict\", final_verdict)\n",
        "builder.add_node(\"technical_analyst2\", technical_analyst)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "builder.set_entry_point(\"technical_analyst\")\n",
        "\n",
        "# Parallel paths\n",
        "\n",
        "builder.add_edge(\"technical_analyst\", \"ethics_expert\")\n",
        "builder.add_edge(\"ethics_expert\", \"legal_advisor\")\n",
        "builder.add_edge(\"legal_advisor\", \"financial_analyst\")\n",
        "builder.add_edge(\"financial_analyst\", \"technical_analyst2\")\n",
        "builder.add_edge(\"technical_analyst2\", \"final_verdict\")\n",
        "builder.add_edge(\"final_verdict\", END)\n",
        "\n",
        "# Compile\n",
        "graph = builder.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfGMmn3TBn75",
        "outputId": "89eacc05-67c4-49e5-cf60-57f06f0684eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inside technical_analyst \n",
            "Inside ethics_expert \n",
            "Inside legal_advisor \n",
            "Inside financial_analyst \n",
            "Inside technical_analyst \n",
            "Inside final_verdict \n",
            "\n",
            "🧾 Final Verdict:\n",
            " **Overall Risk Level: High**\n",
            "\n",
            "**Deployment Recommendation: No**\n",
            "\n",
            "**Short Rationale:** The proposed AI system is fundamentally flawed and poses unacceptable risks across all evaluated dimensions. It is likely illegal under Indian law (infringing on the right to privacy and potentially voyeurism), profoundly unethical due to pervasive surveillance and psychological harm to minors, financially unviable given its high costs and lack of tangible ROI, and technically unfeasible due to inherent inaccuracies, biases, and infrastructure demands. The severe legal, ethical, and reputational liabilities far outweigh any perceived benefits.\n"
          ]
        }
      ],
      "source": [
        "# Run!\n",
        "if __name__ == \"__main__\":\n",
        "    user_input =\"\"\"\n",
        "    We want to deploy an AI system in public schools that uses students' webcam footage during online exams to\n",
        "    detect facial expressions and predict cheating behavior. The system flags suspicious behavior for review\n",
        "    by school authorities.\n",
        "    \"\"\"\n",
        "\n",
        "    initial_state = {\n",
        "        \"proposal\": user_input,\n",
        "        \"legal_feedback\": \"\",\n",
        "        \"ethics_feedback\": \"\",\n",
        "        \"financial_feedback\": \"\",\n",
        "        \"technical_feedback\": \"\",\n",
        "        \"final_verdict\": \"\"\n",
        "    }\n",
        "    result = graph.invoke(initial_state)\n",
        "\n",
        "    print(\"\\n🧾 Final Verdict:\\n\", result[\"final_verdict\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF6FESJ5Bt5d",
        "outputId": "c2125499-0824-40c4-96f3-c431784bc9d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inside technical_analyst \n",
            "Inside ethics_expert \n",
            "Inside legal_advisor \n",
            "Inside financial_analyst \n",
            "Inside technical_analyst \n",
            "Inside final_verdict \n",
            "\n",
            "🧾 Final Verdict:\n",
            " **Final Verdict**\n",
            "\n",
            "*   **Overall Risk Level:** High\n",
            "*   **Deployment Recommendation:** No (for immediate, full city-wide deployment)\n",
            "*   **Short Rationale:** While technically feasible and offering potential benefits, the proposal for immediate city-wide deployment carries substantial legal, ethical, financial, and technical risks. These include significant privacy and surveillance concerns, potential algorithmic bias, immense upfront and ongoing costs, complex integration challenges, and critical cybersecurity vulnerabilities. A phased approach, starting with a detailed feasibility study and a small-scale pilot project with robust safeguards and clear accountability, is strongly recommended before considering broader implementation.\n"
          ]
        }
      ],
      "source": [
        "# Run!\n",
        "if __name__ == \"__main__\":\n",
        "    user_input =\"\"\"\n",
        "We propose a city-wide smart traffic light system that adjusts signals using AI predictions of traffic flow. It requires installation of cameras at major intersections.\n",
        "    \"\"\"\n",
        "\n",
        "    initial_state = {\n",
        "        \"proposal\": user_input,\n",
        "        \"legal_feedback\": \"\",\n",
        "        \"ethics_feedback\": \"\",\n",
        "        \"financial_feedback\": \"\",\n",
        "        \"technical_feedback\": \"\",\n",
        "        \"final_verdict\": \"\"\n",
        "    }\n",
        "    result = graph.invoke(initial_state)\n",
        "\n",
        "    print(\"\\n🧾 Final Verdict:\\n\", result[\"final_verdict\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wUq_Jd1g8qW8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb8f932c-6258-48c6-b58a-90f98f5f4b5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inside technical_analyst \n",
            "Inside ethics_expert \n",
            "Inside legal_advisor \n",
            "Inside financial_analyst \n",
            "Inside technical_analyst \n",
            "Inside final_verdict \n",
            "\n",
            "🧾 Final Verdict:\n",
            " **Overall Risk Level:** High\n",
            "\n",
            "**Deployment Recommendation:** Yes, with Extreme Caution and Strict Adherence to Safeguards\n",
            "\n",
            "**Short Rationale:**\n",
            "The proposed AI system holds significant potential for improving public health by enabling earlier detection of tuberculosis. Technically, it is feasible, and ethically, its intent as a support tool is sound. However, the path to deployment is fraught with **high legal, ethical, and financial risks**. Criminal negligence, patient safety (false negatives), algorithmic bias, data privacy, and substantial development/regulatory costs are major concerns.\n",
            "\n",
            "Deployment is recommended **only if and when** all suggested safeguards – including rigorous clinical validation, transparent disclosure of limitations, robust SOPs mandating independent doctor review, comprehensive training, continuous monitoring, and a clear accountability framework – are meticulously implemented, continuously maintained, and proven effective. Without these stringent measures, the risks outweigh the benefits, making the system unviable and potentially harmful.\n"
          ]
        }
      ],
      "source": [
        "# Run!\n",
        "if __name__ == \"__main__\":\n",
        "    user_input =\"\"\"\n",
        "We propose an AI system in hospitals that analyzes X-ray and MRI scans to assist doctors in detecting early signs of tuberculosis. The system will only be used as a support tool, not as a replacement for doctors.\n",
        "    \"\"\"\n",
        "\n",
        "    initial_state = {\n",
        "        \"proposal\": user_input,\n",
        "        \"legal_feedback\": \"\",\n",
        "        \"ethics_feedback\": \"\",\n",
        "        \"financial_feedback\": \"\",\n",
        "        \"technical_feedback\": \"\",\n",
        "        \"final_verdict\": \"\"\n",
        "    }\n",
        "    result = graph.invoke(initial_state)\n",
        "\n",
        "    print(\"\\n🧾 Final Verdict:\\n\", result[\"final_verdict\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n🧾 Legal Feedback:\\n\", result[\"legal_feedback\"])\n",
        "print(\"\\n🧾 Ethics Feedback:\\n\", result[\"ethics_feedback\"])\n",
        "print(\"\\n🧾 Financial Feedback:\\n\", result[\"financial_feedback\"])\n",
        "print(\"\\n🧾 Technical Feedback:\\n\", result[\"technical_feedback\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFCAuuPnMuoa",
        "outputId": "cc9e0ba2-17c5-49a2-ffe5-448a3dbc0c55"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🧾 Legal Feedback:\n",
            " As your Legal Advisor, I have reviewed your proposal for an AI system in hospitals to assist doctors in detecting early signs of tuberculosis from X-ray and MRI scans. While the intent is commendable and the potential benefits significant, it is crucial to identify and mitigate legal risks, particularly under the Indian Penal Code (IPC).\n",
            "\n",
            "The core principle here is that the AI is a \"support tool, not a replacement for doctors.\" This distinction is vital in determining liability.\n",
            "\n",
            "---\n",
            "\n",
            "### Issues under Indian Penal Code (IPC)\n",
            "\n",
            "The primary risks under IPC revolve around criminal negligence, where an act or omission causes harm or death due to a lack of reasonable care.\n",
            "\n",
            "1.  **Criminal Negligence Leading to Death (Section 304A IPC):**\n",
            "    *   **Scenario:** If the AI system provides an incorrect analysis (e.g., a \"false negative\" missing early signs of TB), and a doctor, relying on this output, fails to diagnose or delays treatment, leading to the patient's death.\n",
            "    *   **Risk:** While the doctor's direct negligence in relying solely on the AI without independent verification would be primary, the developers/hospital could also be implicated if:\n",
            "        *   The AI system was inadequately tested, validated, or known to be faulty.\n",
            "        *   Its limitations, error rates, or biases were not clearly communicated to the medical staff.\n",
            "        *   There was a failure to establish clear protocols for its use, leading to over-reliance.\n",
            "        *   The system was misrepresented as more accurate or reliable than it truly was.\n",
            "\n",
            "2.  **Criminal Negligence Leading to Grievous Hurt (Section 338 IPC) or Hurt (Section 337 IPC):**\n",
            "    *   **Scenario:** Similar to the above, if the AI's error (false negative or false positive) leads to delayed diagnosis, misdiagnosis, or unnecessary invasive procedures, resulting in severe physical harm (e.g., irreversible lung damage due to delayed TB treatment) or lesser harm (e.g., anxiety, discomfort, or minor injury from unnecessary tests).\n",
            "    *   **Risk:** The same principles of liability as under Section 304A would apply, depending on the severity of the harm caused.\n",
            "\n",
            "3.  **Vicarious Liability / Organizational Negligence (Implied under IPC for individuals):**\n",
            "    *   **Scenario:** While IPC primarily targets individuals, the actions (or inactions) of the hospital management or the AI development company's leadership can lead to individual criminal liability if their negligence contributed to the harm.\n",
            "    *   **Risk:**\n",
            "        *   **Hospital Management:** Failure to conduct due diligence on the AI system, inadequate training for staff, lack of robust Standard Operating Procedures (SOPs) for AI use, or failure to monitor the system's performance and address known flaws.\n",
            "        *   **AI Developers/Vendors:** Releasing a product without sufficient clinical validation, failing to disclose known limitations or biases, or making false claims about the system's accuracy.\n",
            "\n",
            "4.  **Data Privacy and Security Breaches (Indirect IPC Relevance):**\n",
            "    *   **Scenario:** Although not directly under IPC for medical negligence, the handling of sensitive patient data (X-rays, MRIs, medical history) by an AI system carries significant risks. A breach could lead to misuse of information.\n",
            "    *   **Risk:** While the primary legal framework for data breaches is the Information Technology Act, 2000, certain actions related to data theft or unauthorized access could potentially fall under IPC sections like theft (Section 378), criminal breach of trust (Section 405), or cheating (Section 415) if there's an element of dishonest intent or wrongful gain/loss. This is a secondary, but important, consideration for any AI system handling sensitive data.\n",
            "\n",
            "---\n",
            "\n",
            "### Suggested Fixes\n",
            "\n",
            "To mitigate the identified legal risks, the following modifications and safeguards are strongly recommended:\n",
            "\n",
            "1.  **Rigorous Clinical Validation and Testing:**\n",
            "    *   **Fix:** The AI system must undergo extensive, multi-center clinical trials in India, with diverse patient populations, to establish its accuracy, sensitivity, and specificity for TB detection in X-ray/MRI scans. All results, including limitations and error rates (false positives/negatives), must be meticulously documented.\n",
            "    *   **IPC Mitigation:** Provides evidence of due diligence and reasonable care in developing and deploying the system, reducing claims of negligence.\n",
            "\n",
            "2.  **Clear Disclosure and Transparency:**\n",
            "    *   **Fix:** All documentation, training materials, and the AI interface itself must clearly state that it is a *support tool* only, not a diagnostic replacement. Its accuracy, limitations, known biases (e.g., performance variations across different demographics or image qualities), and confidence scores must be transparently displayed to the doctor.\n",
            "    *   **IPC Mitigation:** Prevents misrepresentation and ensures doctors are fully aware of the tool's capabilities and limitations, reinforcing their ultimate responsibility.\n",
            "\n",
            "3.  **Robust Standard Operating Procedures (SOPs):**\n",
            "    *   **Fix:** Develop comprehensive SOPs for the use of the AI system. These SOPs must mandate:\n",
            "        *   **Independent Doctor Review:** Every AI analysis *must* be independently reviewed and confirmed by a qualified doctor (radiologist/pulmonologist) before any diagnosis or treatment decision is made. The AI's output should be one data point among others.\n",
            "        *   **Documentation:** Doctors must document their independent assessment, noting whether they agreed or disagreed with the AI's findings and their rationale.\n",
            "        *   **Escalation Protocols:** Clear steps for when the AI's findings conflict with the doctor's initial assessment or other clinical data.\n",
            "    *   **IPC Mitigation:** Establishes a clear framework for responsible use, emphasizing human oversight and accountability, thereby reducing the likelihood of negligence claims against the system or the hospital.\n",
            "\n",
            "4.  **Mandatory Training and Certification:**\n",
            "    *   **Fix:** All medical professionals using the AI system must undergo mandatory training on its functionality, limitations, interpretation of its outputs, and the established SOPs. Certification should be required before use.\n",
            "    *   **IPC Mitigation:** Ensures users are competent and aware of their responsibilities, reducing the risk of negligence due to lack of knowledge.\n",
            "\n",
            "5.  **Informed Patient Consent:**\n",
            "    *   **Fix:** Patients should be informed that an AI system is being used as a *support tool* in their diagnostic process and provide their informed consent.\n",
            "    *   **IPC Mitigation:** Enhances transparency and patient autonomy, reducing potential claims of non-disclosure or unauthorized use of technology.\n",
            "\n",
            "6.  **Continuous Monitoring and Auditing:**\n",
            "    *   **Fix:** Implement a system for continuous monitoring of the AI's performance in a real-world clinical setting. Establish a robust incident reporting mechanism for any discrepancies or errors identified. Regular audits of AI-assisted diagnoses should be conducted.\n",
            "    *   **IPC Mitigation:** Demonstrates ongoing due diligence and a commitment to patient safety, allowing for prompt identification and rectification of issues.\n",
            "\n",
            "7.  **Clear Accountability Framework:**\n",
            "    *   **Fix:** Define clear lines of responsibility for the AI system's performance, maintenance, and updates. This includes responsibilities for the AI developer, the hospital's IT department, and the medical staff.\n",
            "    *   **IPC Mitigation:** Helps in attributing responsibility in case of an adverse event, ensuring that negligent parties can be identified.\n",
            "\n",
            "8.  **Data Security and Privacy Measures:**\n",
            "    *   **Fix:** Implement robust data encryption, access controls, anonymization/pseudonymization techniques, and comply with all relevant data protection laws (e.g., upcoming Digital Personal Data Protection Act, 2023).\n",
            "    *   **IPC Mitigation:** While primarily addressing IT Act concerns, strong data security reduces the risk of data misuse that could indirectly lead to IPC violations.\n",
            "\n",
            "---\n",
            "\n",
            "### Verdict\n",
            "\n",
            "**Legal, with Significant Caveats and Robust Safeguards.**\n",
            "\n",
            "The *concept* of an AI system assisting doctors in diagnosis is not inherently illegal under the Indian Penal Code. However, its *implementation* carries substantial legal risks, primarily related to criminal negligence (Sections 304A, 337, 338 IPC).\n",
            "\n",
            "The system can be legally deployed and operated **IF AND ONLY IF** the suggested modifications and safeguards are rigorously implemented and continuously maintained. The key is to ensure that the AI remains a *tool* that augments human expertise, rather than replacing it, and that all stakeholders (developers, hospital management, and doctors) exercise due diligence and reasonable care in its deployment and use. Without these safeguards, the risk of criminal liability for negligence would be unacceptably high.\n",
            "\n",
            "🧾 Ethics Feedback:\n",
            " Here's an ethical assessment of the proposed AI system:\n",
            "\n",
            "---\n",
            "\n",
            "**Key Ethical Risks**\n",
            "\n",
            "1.  **Patient Safety and Diagnostic Accuracy:**\n",
            "    *   **False Negatives:** The AI might miss early signs of TB, leading to delayed diagnosis, progression of the disease, and potential transmission to others.\n",
            "    *   **False Positives:** The AI might incorrectly flag healthy patients, causing unnecessary anxiety, further invasive tests, and misallocation of healthcare resources.\n",
            "    *   **Over-reliance by Doctors:** Despite being a support tool, doctors might implicitly trust the AI's recommendations more than their own judgment, potentially leading to diagnostic errors if the AI is flawed or encounters an edge case it wasn't trained on.\n",
            "    *   **Model Drift:** The AI's performance might degrade over time due to changes in imaging technology, patient demographics, or evolving disease patterns, without proper retraining and monitoring.\n",
            "\n",
            "2.  **Bias and Fairness (Health Equity):**\n",
            "    *   **Algorithmic Bias:** If the training data is not representative of the diverse patient population (e.g., varying ethnicities, ages, genders, socioeconomic backgrounds, or different types of imaging equipment), the AI may perform less accurately for underrepresented groups. This could exacerbate existing health disparities, particularly for vulnerable populations disproportionately affected by TB.\n",
            "    *   **Geographical Bias:** Training data might be skewed towards certain regions or healthcare systems, leading to poor performance in others with different disease prevalence, imaging protocols, or patient characteristics.\n",
            "\n",
            "3.  **Transparency and Explainability (Trust & Accountability):**\n",
            "    *   **\"Black Box\" Problem:** If the AI cannot explain *why* it made a particular recommendation (e.g., highlighting specific regions of concern and the features it detected), doctors may struggle to critically evaluate its suggestions, leading to a lack of trust and difficulty in identifying potential errors.\n",
            "    *   **Lack of Understanding of Limitations:** Doctors may not fully understand the specific scenarios or types of scans where the AI is less reliable, increasing the risk of misapplication.\n",
            "\n",
            "4.  **Data Privacy and Security:**\n",
            "    *   **Sensitive Data Handling:** X-ray and MRI scans, combined with patient identifiers, constitute highly sensitive medical data. Breaches could lead to severe privacy violations and identity theft.\n",
            "    *   **Data Misuse:** Risks associated with how the data used for training and ongoing operation is stored, accessed, and potentially used for purposes beyond its initial intent.\n",
            "\n",
            "5.  **Accountability and Liability:**\n",
            "    *   **Blame Assignment:** In the event of a diagnostic error leading to patient harm, it can be unclear who is ultimately responsible: the AI developer, the hospital, or the clinician who used the tool. This ambiguity can hinder learning from mistakes and seeking redress.\n",
            "    *   **Erosion of Professional Skill:** Long-term over-reliance on AI could potentially diminish the diagnostic skills of human doctors.\n",
            "\n",
            "6.  **Informed Consent:**\n",
            "    *   Patients may not be aware that an AI system is being used in their diagnostic process. There's an ethical question about whether patients should be informed and given the option to consent to AI involvement in their care.\n",
            "\n",
            "---\n",
            "\n",
            "**Mitigation Suggestions**\n",
            "\n",
            "1.  **Rigorous Validation and Continuous Monitoring:**\n",
            "    *   **Extensive Clinical Trials:** Conduct large-scale, multi-center prospective and retrospective validation studies across diverse patient populations and clinical settings to rigorously assess accuracy, sensitivity, and specificity.\n",
            "    *   **Performance Monitoring:** Implement robust systems for continuous real-time monitoring of the AI's performance in deployment, with mechanisms to detect model drift and trigger retraining or recalibration.\n",
            "    *   **Human-in-the-Loop Design:** Emphasize that the AI is a decision *support* tool. Design the interface to clearly communicate confidence levels and areas of uncertainty, encouraging critical review by the doctor.\n",
            "\n",
            "2.  **Bias Detection and Mitigation:**\n",
            "    *   **Diverse Training Data:** Actively curate and utilize training datasets that are representative of the global population, including diverse demographics (age, gender, ethnicity), disease presentations, and imaging equipment from various geographical regions, especially those with high TB prevalence.\n",
            "    *   **Bias Auditing:** Implement rigorous bias detection and mitigation techniques throughout the AI development lifecycle, regularly auditing the system's performance across different demographic subgroups to ensure equitable outcomes.\n",
            "    *   **Fairness Metrics:** Define and track specific fairness metrics (e.g., equal false positive/negative rates across groups) during development and deployment.\n",
            "\n",
            "3.  **Transparency and Explainability (XAI):**\n",
            "    *   **Explainable AI (XAI) Features:** Integrate XAI techniques that allow the system to highlight specific regions of interest on the scans and provide a clear, interpretable rationale for its suggestions (e.g., heatmaps, saliency maps).\n",
            "    *   **Comprehensive Documentation:** Provide detailed documentation to clinicians on the AI's design, training data, known limitations, confidence scores, and best practices for interpreting its outputs.\n",
            "    *   **Training for Clinicians:** Offer comprehensive training for doctors on how to effectively use the AI, understand its outputs, and recognize its limitations.\n",
            "\n",
            "4.  **Robust Data Privacy and Security:**\n",
            "    *   **State-of-the-Art Security:** Implement strong encryption, access controls, anonymization/pseudonymization techniques, and regular security audits to protect sensitive patient data.\n",
            "    *   **Regulatory Compliance:** Ensure strict adherence to relevant data protection regulations (e.g., HIPAA, GDPR) and establish clear data governance policies.\n",
            "\n",
            "5.  **Clear Accountability Frameworks:**\n",
            "    *   **Legal and Ethical Guidelines:** Develop clear legal and ethical frameworks defining responsibilities among AI developers, hospitals, and clinicians in the event of diagnostic errors.\n",
            "    *   **Professional Standards:** Integrate AI use into medical professional guidelines and training curricula, emphasizing the doctor's ultimate responsibility for patient care.\n",
            "\n",
            "6.  **Informed Patient Consent:**\n",
            "    *   **Patient Communication:** Inform patients that AI tools may be used as part of their diagnostic process, explaining its role as a support tool and not a replacement for human expertise. Provide clear, accessible information about the system.\n",
            "    *   **Opt-out Option:** Where feasible and appropriate, offer patients an option to decline the use of AI in their diagnostic process.\n",
            "\n",
            "---\n",
            "\n",
            "**Verdict: Ethical (with significant caveats)**\n",
            "\n",
            "The proposed AI system is **Ethical in Principle**, given its stated purpose as a *support tool* to assist doctors in detecting early signs of tuberculosis. The potential benefits of earlier and more accurate TB detection, especially in high-burden areas or for large-scale screening, are substantial and could significantly improve public health outcomes.\n",
            "\n",
            "However, its ethical implementation is **highly conditional** on the robust and continuous application of the mitigation strategies outlined above. Without addressing the critical risks related to accuracy, bias, transparency, data security, and accountability, the system could inadvertently cause harm, exacerbate health inequalities, and erode trust in AI in healthcare. The \"support tool\" designation is crucial; any move towards autonomous diagnosis would fundamentally alter this verdict.\n",
            "\n",
            "🧾 Financial Feedback:\n",
            " ## Financial Assessment: AI System for Early Tuberculosis Detection\n",
            "\n",
            "**Proposal:** An AI system in hospitals analyzing X-ray and MRI scans to assist doctors in detecting early signs of tuberculosis, used as a support tool, not a replacement.\n",
            "\n",
            "---\n",
            "\n",
            "### Estimated Costs\n",
            "\n",
            "The costs for such a sophisticated AI system can be substantial, encompassing development, deployment, and ongoing operations. We'll break these down into initial capital expenditure (CapEx) and recurring operational expenditure (OpEx).\n",
            "\n",
            "**1. Initial Capital Expenditure (CapEx):**\n",
            "\n",
            "*   **AI Model Development & Training:**\n",
            "    *   **Data Acquisition & Annotation:** Sourcing, anonymizing, and expert annotation (radiologists, pulmonologists) of a massive dataset of X-ray and MRI scans (both TB positive and negative, across various stages and demographics). This is often the most significant cost.\n",
            "        *   *Estimate:* **$1,500,000 - $4,000,000**\n",
            "    *   **Algorithm Development & Engineering:** Salaries for AI/ML engineers, data scientists, medical imaging specialists, software architects. Includes R&D, model selection, training, and initial validation.\n",
            "        *   *Estimate:* **$1,000,000 - $3,000,000**\n",
            "    *   **High-Performance Computing (HPC) Infrastructure:** For model training (GPUs, specialized servers, cloud compute credits).\n",
            "        *   *Estimate:* **$200,000 - $800,000**\n",
            "    *   **Software Licenses & Tools:** For development environments, data management, MLOps platforms.\n",
            "        *   *Estimate:* **$50,000 - $200,000**\n",
            "*   **Regulatory & Certification:** Costs associated with obtaining necessary medical device approvals (e.g., FDA, CE Mark), clinical trials, and legal counsel. This is a multi-year, intensive process.\n",
            "    *   *Estimate:* **$1,000,000 - $5,000,000** (highly variable based on jurisdiction and complexity)\n",
            "*   **Initial Deployment & Integration (per hospital):**\n",
            "    *   **Hardware:** On-premise servers/GPUs (if not cloud-based), network infrastructure upgrades.\n",
            "        *   *Estimate:* **$30,000 - $100,000**\n",
            "    *   **Software Integration:** Connecting with existing Picture Archiving and Communication Systems (PACS), Electronic Health Records (EHR), and hospital IT infrastructure. Requires custom API development and testing.\n",
            "        *   *Estimate:* **$50,000 - $200,000**\n",
            "    *   **Installation & Configuration:** On-site technical staff for setup and initial testing.\n",
            "        *   *Estimate:* **$10,000 - $30,000**\n",
            "\n",
            "**Total Estimated Initial CapEx (for core system + regulatory + pilot hospital): $3,840,000 - $13,230,000**\n",
            "\n",
            "**2. Recurring Operational Expenditure (OpEx):**\n",
            "\n",
            "*   **Cloud Hosting/Infrastructure (if cloud-based):** Ongoing costs for compute, storage, and data transfer.\n",
            "    *   *Estimate:* **$5,000 - $20,000 per hospital per month** (depending on scan volume)\n",
            "*   **Maintenance & Updates:**\n",
            "    *   **Model Retraining & Improvement:** Regular updates to the AI model with new data, addressing performance drift, and incorporating new research.\n",
            "        *   *Estimate:* **$300,000 - $1,000,000 per year**\n",
            "    *   **Software Maintenance & Bug Fixes:** Ongoing support for the application and integration layers.\n",
            "        *   *Estimate:* **$100,000 - $400,000 per year**\n",
            "*   **Technical Support & Helpdesk:** For hospitals and end-users.\n",
            "    *   *Estimate:* **$50,000 - $200,000 per year**\n",
            "*   **Compliance & Audits:** Ongoing regulatory compliance, data privacy audits (e.g., HIPAA, GDPR).\n",
            "    *   *Estimate:* **$50,000 - $150,000 per year**\n",
            "*   **Training & User Adoption:** Training for radiologists, technicians, and IT staff on system usage and interpretation.\n",
            "    *   *Estimate:* **$20,000 - $50,000 per hospital per year** (initial year higher)\n",
            "\n",
            "**Total Estimated Annual OpEx (for core system + 10 hospitals): $1,120,000 - $3,900,000**\n",
            "\n",
            "---\n",
            "\n",
            "### ROI & Risks\n",
            "\n",
            "**Return on Investment (ROI) - Potential Benefits:**\n",
            "\n",
            "*   **Improved Patient Outcomes & Reduced Mortality:** Early detection of TB leads to earlier treatment, significantly improving prognosis and reducing severe complications. This is the primary, non-monetary ROI.\n",
            "*   **Reduced Healthcare Costs (Long-Term):**\n",
            "    *   **Lower Treatment Costs:** Treating early-stage TB is less expensive than treating advanced, drug-resistant, or disseminated forms.\n",
            "    *   **Shorter Hospital Stays:** Early diagnosis can reduce the duration and frequency of hospitalizations.\n",
            "    *   **Reduced Diagnostic Costs:** Potentially fewer follow-up tests, biopsies, or more invasive procedures if AI provides strong early indicators.\n",
            "    *   **Reduced Transmission:** Early diagnosis and isolation reduce community and nosocomial (hospital-acquired) spread, saving public health resources.\n",
            "*   **Operational Efficiency & Productivity:**\n",
            "    *   **Faster Diagnosis Turnaround:** AI can process scans much faster than human review, especially for initial screening.\n",
            "    *   **Optimized Radiologist Workflow:** AI can triage scans, highlight suspicious areas, and reduce the burden of sifting through normal scans, allowing radiologists to focus on complex cases. This can increase throughput.\n",
            "    *   **Consistency:** AI provides a consistent, objective analysis, reducing inter-observer variability.\n",
            "*   **Enhanced Hospital Reputation & Competitive Advantage:** Positioning the hospital as an innovator in patient care and technology.\n",
            "*   **Research & Grant Opportunities:** Access to funding for further AI development and clinical studies.\n",
            "*   **Public Health Impact:** Significant contribution to global TB eradication efforts, especially in high-burden regions.\n",
            "\n",
            "**Risks:**\n",
            "\n",
            "*   **Accuracy & Performance Risk:**\n",
            "    *   **False Positives:** Can lead to unnecessary follow-up tests, patient anxiety, and increased healthcare costs.\n",
            "    *   **False Negatives:** The most critical risk. Missing early TB can lead to delayed treatment, disease progression, increased transmission, and severe patient harm, resulting in significant legal and reputational damage.\n",
            "    *   **Bias:** AI models can inherit biases from training data (e.g., underperforming on certain demographics, scan types, or disease presentations).\n",
            "*   **Regulatory & Legal Risk:**\n",
            "    *   **Approval Delays/Denial:** The rigorous approval process can be lengthy and costly, with no guarantee of success.\n",
            "    *   **Liability:** Clear definition of responsibility if the AI system contributes to a misdiagnosis. Who is liable – the developer, the hospital, or the doctor?\n",
            "    *   **Data Privacy & Security:** Handling sensitive patient medical data requires robust security measures and strict compliance with regulations (HIPAA, GDPR). Breaches can lead to massive fines and reputational damage.\n",
            "*   **Integration & Adoption Risk:**\n",
            "    *   **Interoperability Challenges:** Integrating with diverse and often legacy hospital IT systems can be complex, costly, and time-consuming.\n",
            "    *   **User Resistance:** Doctors and staff may be hesitant to trust or adopt the AI system, especially if it disrupts established workflows or if its benefits aren't clearly demonstrated.\n",
            "    *   **Over-reliance:** Doctors might become overly reliant on the AI, potentially leading to a decline in critical thinking or overlooking subtle signs the AI missed.\n",
            "*   **Financial & Market Risk:**\n",
            "    *   **Cost Overruns:** Development and deployment costs often exceed initial estimates.\n",
            "    *   **Scalability:** Difficulty in scaling the system to multiple hospitals or regions without significant additional investment.\n",
            "    *   **Market Acceptance:** Despite the benefits, hospitals may be slow to adopt due to budget constraints, perceived risks, or lack of clear ROI demonstration.\n",
            "    *   **Competition:** Emergence of competing, potentially more advanced or cost-effective, solutions.\n",
            "*   **Maintenance & Obsolescence Risk:**\n",
            "    *   **Model Drift:** AI models can degrade over time as new data patterns emerge or patient populations change, requiring continuous retraining.\n",
            "    *   **Technological Obsolescence:** Rapid advancements in AI could render the current system outdated.\n",
            "\n",
            "---\n",
            "\n",
            "### Verdict (Financially Viable/Not Viable)\n",
            "\n",
            "**Verdict: Potentially Financially Viable, but with Significant Caveats and a High-Risk Profile.**\n",
            "\n",
            "While the initial investment is substantial, the long-term ROI, particularly in terms of **improved patient outcomes, reduced public health burden, and potential cost savings from early detection and prevention of advanced disease,** makes this proposal attractive. The non-monetary benefits (reputation, ethical impact) are also very strong.\n",
            "\n",
            "**However, viability hinges on several critical factors:**\n",
            "\n",
            "1.  **Demonstrable Accuracy & Reliability:** The system *must* achieve very high sensitivity and specificity, especially in detecting early-stage TB, with robust validation across diverse populations. Failure here would negate all benefits and introduce severe risks.\n",
            "2.  **Regulatory Approval:** Obtaining necessary medical device certifications is a long, expensive, and uncertain process. Without it, the system cannot be deployed clinically.\n",
            "3.  **Clear Value Proposition & ROI Model for Hospitals:** Hospitals need to see a tangible financial benefit (e.g., reduced readmissions, optimized staff time, fewer advanced cases) to justify the per-hospital deployment and operational costs. A SaaS model with a clear cost-benefit analysis will be crucial.\n",
            "4.  **Effective Integration & User Adoption Strategy:** The system must seamlessly integrate into existing workflows and be trusted by medical professionals.\n",
            "5.  **Sustainable Funding Model:** A combination of direct sales/subscriptions to hospitals, government grants (given the public health impact of TB), and potentially partnerships with NGOs could support ongoing development and deployment.\n",
            "\n",
            "**Recommendation:**\n",
            "\n",
            "Proceed with a **phased approach**, starting with:\n",
            "1.  **Rigorous R&D and Clinical Validation:** Focus on achieving top-tier accuracy and securing regulatory approvals.\n",
            "2.  **Pilot Programs:** Implement in a few select hospitals to gather real-world data on performance, integration challenges, user feedback, and actual cost savings.\n",
            "3.  **Robust Business Case Development:** Quantify the ROI for hospitals, considering both direct financial savings and indirect benefits.\n",
            "4.  **Strong Legal & Ethical Framework:** Address liability, data privacy, and bias proactively.\n",
            "\n",
            "Without a clear path through these challenges, the significant upfront investment and ongoing operational costs, coupled with the high risks, could render the project financially unviable. With careful planning and execution, however, this system has the potential to be a transformative and financially sustainable solution in global health.\n",
            "\n",
            "🧾 Technical Feedback:\n",
            " As a Technical Analyst, I've evaluated your proposal for an AI system to detect early signs of tuberculosis (TB) from X-ray and MRI scans, intended as a support tool for doctors.\n",
            "\n",
            "---\n",
            "\n",
            "### Feasibility Issues\n",
            "\n",
            "1.  **Data Acquisition and Annotation:**\n",
            "    *   **Volume and Diversity:** Requires an extremely large, diverse, and high-quality dataset of X-ray and MRI scans from various patient demographics (age, gender, ethnicity), different stages of TB (especially early signs), and various scanner models/protocols.\n",
            "    *   **Expert Annotation:** Each scan needs to be meticulously annotated by multiple expert radiologists to identify and delineate early TB signs. This is a time-consuming, expensive, and bottleneck-prone process.\n",
            "    *   **Data Imbalance:** Early signs of TB might be rare in a general population dataset, leading to class imbalance issues that can hinder model training and performance.\n",
            "    *   **Data Privacy and Ethics:** Strict adherence to patient data privacy regulations (e.g., HIPAA, GDPR) and ethical guidelines for data collection and usage is paramount, adding complexity and cost.\n",
            "\n",
            "2.  **Model Development and Training:**\n",
            "    *   **Computational Resources:** Training state-of-the-art deep learning models on large medical image datasets demands significant computational power (high-end GPUs, cloud infrastructure), which can be costly.\n",
            "    *   **Algorithm Complexity:** Developing robust algorithms capable of discerning subtle, early signs of TB from normal variations or other pathologies (e.g., other infections, benign findings) is technically challenging.\n",
            "    *   **Generalizability:** Ensuring the model performs consistently and accurately across different hospital settings, scanner types, and patient populations (which may differ from the training data) is a major hurdle.\n",
            "\n",
            "3.  **Integration with Hospital Systems:**\n",
            "    *   **PACS/EHR Integration:** Seamless integration with existing Picture Archiving and Communication Systems (PACS) for image retrieval and Electronic Health Record (EHR) systems for contextual patient data and result reporting is complex and requires robust APIs and IT infrastructure.\n",
            "    *   **Regulatory Approval:** As a medical device, the system will require rigorous regulatory approval (e.g., FDA in the US, CE Mark in Europe), involving extensive validation, clinical trials, and documentation, which is a lengthy and expensive process.\n",
            "    *   **IT Infrastructure and Cybersecurity:** Hospitals need robust IT infrastructure to support the system, and stringent cybersecurity measures are essential to protect sensitive patient data.\n",
            "\n",
            "4.  **Clinical Workflow Adoption:**\n",
            "    *   **User Interface/Experience:** The system must have an intuitive and efficient user interface that integrates smoothly into the existing clinical workflow without adding significant burden to doctors.\n",
            "    *   **Trust and Acceptance:** Gaining the trust and acceptance of medical professionals requires demonstrating consistent accuracy, reliability, and clear benefits, along with proper training.\n",
            "\n",
            "### Known Limitations\n",
            "\n",
            "1.  **False Positives and False Negatives:**\n",
            "    *   **False Positives:** The system may flag non-TB findings as suspicious, leading to unnecessary follow-up tests, increased patient anxiety, and higher healthcare costs.\n",
            "    *   **False Negatives:** Critically, missing early signs of TB can have severe consequences for patient health and public health (due to delayed treatment and potential transmission).\n",
            "    *   **Subtlety of Early Signs:** Early TB can be extremely subtle and mimic other conditions, making it inherently difficult for even human experts, let alone AI, to perfectly distinguish.\n",
            "\n",
            "2.  **Lack of Clinical Context (Black Box Problem):**\n",
            "    *   **Image-Only Analysis:** The AI system primarily analyzes images and lacks access to crucial clinical context such as patient history, symptoms, lab results, travel history, and physical examination findings, which are vital for a comprehensive diagnosis.\n",
            "    *   **Explainability:** Many deep learning models are \"black boxes,\" making it difficult to understand *why* a particular decision was made. Doctors need explainable AI to trust and validate its recommendations, especially in critical medical decisions.\n",
            "\n",
            "3.  **Bias and Generalizability:**\n",
            "    *   **Data Bias:** If the training data is not perfectly representative of the diverse patient population, the model may exhibit bias, performing poorly on underrepresented groups or specific demographics, potentially exacerbating health disparities.\n",
            "    *   **Domain Shift:** Performance can degrade when applied to data from different scanner manufacturers, image acquisition protocols, or patient populations than those used in training.\n",
            "\n",
            "4.  **Dynamic Nature of Disease:**\n",
            "    *   TB can manifest in various forms and stages, and its radiological appearance can evolve. The AI needs to be robust enough to handle this variability, which is challenging.\n",
            "\n",
            "5.  **Maintenance and Updates:**\n",
            "    *   AI models are not \"set and forget.\" They require continuous monitoring, retraining with new data, and updates to maintain performance as medical knowledge evolves and data characteristics change (data drift, concept drift).\n",
            "\n",
            "### Verdict\n",
            "\n",
            "**Feasible**\n",
            "\n",
            "While significant challenges exist in data acquisition, model development, regulatory approval, and clinical integration, the proposal is **feasible** given the current advancements in AI and medical imaging. The crucial aspect is that the system is proposed as a **support tool, not a replacement for doctors.** This significantly lowers the bar for absolute perfection and allows for human oversight to mitigate the risks of false positives and negatives.\n",
            "\n",
            "Achieving feasibility will require substantial investment in:\n",
            "*   High-quality, diverse, and ethically sourced datasets.\n",
            "*   Expert AI/ML engineering and medical domain knowledge.\n",
            "*   Robust validation and regulatory compliance.\n",
            "*   Careful integration into clinical workflows with a focus on user experience and explainability.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pbP-5xYmYkFS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}